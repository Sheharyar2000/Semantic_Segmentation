{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3o9agu2ozGy",
        "outputId": "e71c21f7-3acf-44db-dd78-7c6e5857a919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Paths to your ZIP files in Drive\n",
        "gta5_zip = \"/content/drive/MyDrive/Semantic_Segmentation/GTA5.zip\"\n",
        "cityscapes_zip = \"/content/drive/MyDrive/Semantic_Segmentation/Cityscapes.zip\"\n",
        "\n",
        "# Extraction destination\n",
        "extract_path = \"/content/datasets\"\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(gta5_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "with zipfile.ZipFile(cityscapes_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"✅ Datasets extracted\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8LW4amFsYlC",
        "outputId": "5326ea64-e63f-4ea4-f4fb-7db1d0f159fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Datasets extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "base_path = \"/content/datasets/Cityscapes/Cityspaces\"\n",
        "\n",
        "if os.path.exists(base_path):\n",
        "    shutil.move(os.path.join(base_path, \"gtFine\"), \"/content/datasets/Cityscapes/gtFine\")\n",
        "    shutil.move(os.path.join(base_path, \"images\"), \"/content/datasets/Cityscapes/leftImg8bit\")\n",
        "    shutil.rmtree(base_path)\n",
        "    print(\"✅ Fixed Cityscapes folder structure\")\n",
        "else:\n",
        "    print(\"⚠️ Folder structure already appears correct.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpgHcVmXu3GA",
        "outputId": "b6390b89-2218-440e-b788-da5437e6018c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fixed Cityscapes folder structure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the datasets with combined augmentations"
      ],
      "metadata": {
        "id": "wPaZrTFL195I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as TF\n",
        "from PIL import Image\n",
        "\n",
        "# ✅ GTA5 → Cityscapes label remapping\n",
        "GTA5_TO_CITYSCAPES = {\n",
        "    7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 15: 5, 17: 6, 19: 7, 20: 8,\n",
        "    21: 9, 22: 10, 23: 11, 24: 12, 26: 13, 27: 14, 28: 15,\n",
        "    31: 16, 32: 17, 33: 18\n",
        "}\n",
        "\n",
        "class GTA5Dataset(Dataset):\n",
        "    def __init__(self, root, transform=None, target_transform=None, apply_aug=False):\n",
        "        self.image_dir = os.path.join(root, \"images\")\n",
        "        self.label_dir = os.path.join(root, \"labels\")\n",
        "        self.images = sorted(os.listdir(self.image_dir))\n",
        "        self.labels = sorted(os.listdir(self.label_dir))\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.apply_aug = apply_aug\n",
        "\n",
        "        self.color_jitter = transforms.ColorJitter(\n",
        "            brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def encode_labels(self, mask):\n",
        "        remapped = np.full_like(mask, 255)\n",
        "        for gta_id, city_id in GTA5_TO_CITYSCAPES.items():\n",
        "            remapped[mask == gta_id] = city_id\n",
        "        return remapped\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.label_dir, self.labels[idx])\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path)\n",
        "\n",
        "        if self.apply_aug:\n",
        "            if random.random() < 0.5:\n",
        "                img = TF.hflip(img)\n",
        "                mask = TF.hflip(mask)\n",
        "            if random.random() < 0.5:\n",
        "                img = self.color_jitter(img)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "            mask = self.encode_labels(mask.squeeze().numpy())\n",
        "            mask = torch.from_numpy(mask).long().unsqueeze(0)\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "class CityscapesDataset(Dataset):\n",
        "    def __init__(self, root, split='val', transform=None, target_transform=None):\n",
        "        self.image_dir = os.path.join(root, \"leftImg8bit\", split)\n",
        "        self.label_dir = os.path.join(root, \"gtFine\", split)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        for city in os.listdir(self.image_dir):\n",
        "            img_folder = os.path.join(self.image_dir, city)\n",
        "            label_folder = os.path.join(self.label_dir, city)\n",
        "\n",
        "            for file_name in os.listdir(img_folder):\n",
        "                if file_name.endswith(\"_leftImg8bit.png\"):\n",
        "                    base = file_name.replace(\"_leftImg8bit.png\", \"\")\n",
        "                    img_path = os.path.join(img_folder, file_name)\n",
        "                    label_path = os.path.join(label_folder, base + \"_gtFine_labelTrainIds.png\")\n",
        "\n",
        "                    if os.path.exists(label_path):\n",
        "                        self.images.append(img_path)\n",
        "                        self.labels.append(label_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        mask = Image.open(self.labels[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "\n",
        "        return img, mask\n"
      ],
      "metadata": {
        "id": "vRRLiTAw2Fgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# ✅ Image and mask transforms\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 1024)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 1024), interpolation=Image.NEAREST),\n",
        "    transforms.PILToTensor()\n",
        "])\n",
        "\n",
        "# ✅ Initialize datasets with transforms and augmentation\n",
        "gta5_dataset = GTA5Dataset(\n",
        "    root=\"/content/datasets/GTA5\",\n",
        "    transform=image_transform,\n",
        "    target_transform=mask_transform,\n",
        "    apply_aug=True  # ✅ Combined augmentation\n",
        ")\n",
        "\n",
        "cityscapes_val = CityscapesDataset(\n",
        "    root=\"/content/datasets/Cityscapes\",\n",
        "    split='val',\n",
        "    transform=image_transform,\n",
        "    target_transform=mask_transform\n",
        ")\n",
        "\n",
        "# ✅ Create DataLoaders\n",
        "train_loader = DataLoader(gta5_dataset, batch_size=2, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(cityscapes_val, batch_size=2, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"✅ Train loader: {len(train_loader)} batches | Val loader: {len(val_loader)} batches\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHGX5F1b5OJ-",
        "outputId": "b1601fce-b77f-4290-baed-0b284b66c2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train loader: 1250 batches | Val loader: 250 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Clone the official MLDL2024 project repo (if needed)\n",
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git\n",
        "\n",
        "# ✅ Add it to the system path\n",
        "import sys\n",
        "sys.path.append(\"/content/MLDL2024_project1\")\n",
        "\n",
        "# ✅ Import BiSeNet\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "print(\"✅ BiSeNet import successful.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkKSQrsQ6Ed-",
        "outputId": "ba88066b-6b01-477c-db8f-bd41cc20f93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLDL2024_project1'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 34 (delta 9), reused 3 (delta 3), pack-reused 15 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34/34), 11.29 KiB | 11.29 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "✅ BiSeNet import successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# ✅ Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ Create the BiSeNet model with ResNet18\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "model = model.to(device)\n",
        "print(\"✅ BiSeNet with ResNet18 initialized and moved to\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNiNRdFW6ngX",
        "outputId": "81904512-ae4b-4b15-ed30-983e248521e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 215MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:00<00:00, 207MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ BiSeNet with ResNet18 initialized and moved to cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "# ✅ Loss function (ignore index 255, which means \"void\")\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "# ✅ Optimizer (SGD with momentum and weight decay)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# ✅ AMP scaler (for mixed precision training)\n",
        "scaler = GradScaler()\n",
        "\n",
        "print(\"✅ Loss, optimizer, and AMP scaler initialized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuJAEebU69Up",
        "outputId": "86df23f6-d073-4862-eaf2-1b6932d265be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loss, optimizer, and AMP scaler initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "# ✅ Training configuration\n",
        "epochs = 50\n",
        "best_val_loss = float(\"inf\")\n",
        "save_path = \"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_aug_combined.pth\"\n",
        "\n",
        "print(\"🟢 Starting BiSeNet training with Combined Augmentations...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    loop = tqdm(train_loader, total=len(train_loader), desc=f\"Epoch [{epoch+1}/{epochs}]\", leave=False)\n",
        "\n",
        "    for images, masks in loop:\n",
        "        images = images.to(device)\n",
        "        masks = masks.squeeze(1).long().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            out, aux1, aux2 = model(images)\n",
        "            loss1 = criterion(out, masks)\n",
        "            loss2 = criterion(aux1, masks)\n",
        "            loss3 = criterion(aux2, masks)\n",
        "            loss = loss1 + 0.4 * (loss2 + loss3)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # ✅ Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_imgs, val_masks in val_loader:\n",
        "            val_imgs = val_imgs.to(device)\n",
        "            val_masks = val_masks.squeeze(1).long().to(device)\n",
        "\n",
        "            with autocast():\n",
        "                val_out = model(val_imgs)\n",
        "                val_loss_batch = criterion(val_out, val_masks)\n",
        "\n",
        "            val_loss += val_loss_batch.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    # ✅ Save best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"💾 Best model saved at epoch {epoch+1} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # ✅ GPU cleanup\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    mem_free = torch.cuda.mem_get_info()[0] / (1024 ** 3)\n",
        "\n",
        "    print(f\"✅ Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Free GPU: {mem_free:.2f} GB\")\n",
        "\n",
        "print(\"🏁 Combined augmentation training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9DfO_Ik72EH",
        "outputId": "0eaf8ed2-e030-4839-c5c1-e02c2a9abcb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟢 Starting BiSeNet training with Combined Augmentations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Best model saved at epoch 1 | Val Loss: 2.9837\n",
            "✅ Epoch 1 | Train Loss: 1.4100 | Val Loss: 2.9837 | Free GPU: 38.47 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Best model saved at epoch 2 | Val Loss: 2.8402\n",
            "✅ Epoch 2 | Train Loss: 0.9861 | Val Loss: 2.8402 | Free GPU: 38.45 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 3 | Train Loss: 0.8441 | Val Loss: 4.0824 | Free GPU: 38.39 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 4 | Train Loss: 0.8121 | Val Loss: 3.7960 | Free GPU: 38.43 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 5 | Train Loss: 0.9374 | Val Loss: 4.2916 | Free GPU: 38.43 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 6 | Train Loss: 0.7537 | Val Loss: 3.5445 | Free GPU: 38.52 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 7 | Train Loss: 0.6942 | Val Loss: 3.5713 | Free GPU: 38.43 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Best model saved at epoch 8 | Val Loss: 2.6615\n",
            "✅ Epoch 8 | Train Loss: 0.6840 | Val Loss: 2.6615 | Free GPU: 38.40 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 9 | Train Loss: 0.6425 | Val Loss: 5.0285 | Free GPU: 38.56 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 10 | Train Loss: 0.6011 | Val Loss: 4.1269 | Free GPU: 38.49 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 11 | Train Loss: 0.5850 | Val Loss: 3.7501 | Free GPU: 38.48 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 12 | Train Loss: 0.5462 | Val Loss: 4.0968 | Free GPU: 38.54 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 13 | Train Loss: 0.6119 | Val Loss: 4.2419 | Free GPU: 38.51 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 14 | Train Loss: 0.5261 | Val Loss: 3.7358 | Free GPU: 38.51 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 15 | Train Loss: 0.5050 | Val Loss: 3.4012 | Free GPU: 38.39 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 16 | Train Loss: 0.4922 | Val Loss: 4.7972 | Free GPU: 38.53 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 17 | Train Loss: 0.4748 | Val Loss: 4.9053 | Free GPU: 38.52 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 18 | Train Loss: 0.4756 | Val Loss: 3.8417 | Free GPU: 38.39 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 19 | Train Loss: 0.4536 | Val Loss: 4.0490 | Free GPU: 38.48 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 20 | Train Loss: 0.4371 | Val Loss: 5.9471 | Free GPU: 38.51 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 21 | Train Loss: 0.4307 | Val Loss: 7.2828 | Free GPU: 38.41 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 22 | Train Loss: 0.4153 | Val Loss: 4.2896 | Free GPU: 38.44 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 23 | Train Loss: 0.3959 | Val Loss: 6.4983 | Free GPU: 38.45 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 24 | Train Loss: 0.3920 | Val Loss: 4.3770 | Free GPU: 38.39 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 25 | Train Loss: 0.3912 | Val Loss: 5.0916 | Free GPU: 38.46 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 26 | Train Loss: 0.3774 | Val Loss: 5.0571 | Free GPU: 38.46 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 27 | Train Loss: 0.3710 | Val Loss: 5.7845 | Free GPU: 38.41 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 28 | Train Loss: 0.3750 | Val Loss: 3.3858 | Free GPU: 38.50 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 29 | Train Loss: 0.3696 | Val Loss: 4.0508 | Free GPU: 38.46 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 30 | Train Loss: 0.3509 | Val Loss: 3.7895 | Free GPU: 38.50 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 31 | Train Loss: 0.3453 | Val Loss: 5.0836 | Free GPU: 38.44 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 32 | Train Loss: 0.3359 | Val Loss: 6.0133 | Free GPU: 38.44 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 33 | Train Loss: 0.3335 | Val Loss: 4.2513 | Free GPU: 38.54 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 34 | Train Loss: 0.3374 | Val Loss: 4.2643 | Free GPU: 38.49 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 35 | Train Loss: 0.3304 | Val Loss: 4.4273 | Free GPU: 38.47 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 36 | Train Loss: 0.3312 | Val Loss: 6.3950 | Free GPU: 38.47 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 37 | Train Loss: 0.3137 | Val Loss: 5.9583 | Free GPU: 38.46 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 38 | Train Loss: 0.3106 | Val Loss: 5.1779 | Free GPU: 38.58 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 39 | Train Loss: 0.3018 | Val Loss: 6.0585 | Free GPU: 38.51 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 40 | Train Loss: 0.3194 | Val Loss: 4.5392 | Free GPU: 38.40 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 41 | Train Loss: 0.2971 | Val Loss: 4.0968 | Free GPU: 38.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 42 | Train Loss: 0.2899 | Val Loss: 6.4808 | Free GPU: 38.55 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 43 | Train Loss: 0.2911 | Val Loss: 4.6964 | Free GPU: 38.54 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 44 | Train Loss: 0.2841 | Val Loss: 5.2253 | Free GPU: 38.43 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 45 | Train Loss: 0.2790 | Val Loss: 4.5851 | Free GPU: 38.55 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 46 | Train Loss: 0.2891 | Val Loss: 4.8917 | Free GPU: 38.41 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 47 | Train Loss: 0.3041 | Val Loss: 3.9848 | Free GPU: 38.52 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 48 | Train Loss: 0.2847 | Val Loss: 5.1047 | Free GPU: 38.51 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 49 | Train Loss: 0.2829 | Val Loss: 4.5508 | Free GPU: 38.49 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 50 | Train Loss: 0.2904 | Val Loss: 6.3403 | Free GPU: 38.52 GB\n",
            "🏁 Combined augmentation training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_aug_combined.pth\"))\n",
        "model.eval()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52wve5Pe8r-6",
        "outputId": "7e4e3e4f-fafe-4ec0-fee8-cae2e2cc2441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiSeNet(\n",
              "  (saptial_path): Spatial_path(\n",
              "    (convblock1): ConvBlock(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (convblock2): ConvBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (convblock3): ConvBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (context_path): resnet18(\n",
              "    (features): ResNet(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "    )\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (attention_refinement_module1): AttentionRefinementModule(\n",
              "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (attention_refinement_module2): AttentionRefinementModule(\n",
              "    (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (supervision1): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (supervision2): Conv2d(512, 19, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (feature_fusion_module): FeatureFusionModule(\n",
              "    (convblock): ConvBlock(\n",
              "      (conv1): Conv2d(1024, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (conv1): Conv2d(19, 19, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (relu): ReLU()\n",
              "    (conv2): Conv2d(19, 19, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (sigmoid): Sigmoid()\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (conv): Conv2d(19, 19, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save after training (if not already saved inside loop)\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_aug_combined.pth\")\n",
        "print(\"✅ Model saved to Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBwfb635HBwf",
        "outputId": "3189289f-7270-43e9-bee0-cacad83b1eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved to Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Reload model\n",
        "model_aug2 = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "model_aug2.load_state_dict(torch.load(\"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_aug_combined.pth\"))\n",
        "model_aug2 = model_aug2.to('cuda')\n",
        "model_aug2.eval()\n",
        "\n",
        "# Validation mIoU\n",
        "def evaluate_miou(model, dataloader, num_classes=19):\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    iou_list = []\n",
        "    hist = torch.zeros(num_classes, num_classes).to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=\"🔍 Evaluating mIoU\"):\n",
        "            images = images.to('cuda')\n",
        "            labels = labels.squeeze(1).to('cuda')\n",
        "\n",
        "            preds = model(images)\n",
        "            preds = torch.argmax(preds, dim=1)\n",
        "\n",
        "            for p, t in zip(preds, labels):\n",
        "                hist += torch.bincount(\n",
        "                    num_classes * t.flatten() + p.flatten(),\n",
        "                    minlength=num_classes ** 2\n",
        "                ).reshape(num_classes, num_classes)\n",
        "\n",
        "    iou = hist.diag() / (hist.sum(1) + hist.sum(0) - hist.diag() + 1e-6)\n",
        "    for i, val in enumerate(iou):\n",
        "        print(f\"{i:02d}: {val:.4f}\")\n",
        "    print(f\"\\n📊 Final mIoU with augmentation: {iou.mean():.4f}\")\n",
        "\n",
        "evaluate_miou(model_aug2, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URgBPEswHKQE",
        "outputId": "ba95d321-51bf-4c8a-f708-f89ff9e24656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Evaluating mIoU: 100%|██████████| 250/250 [00:30<00:00,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00: 0.6954\n",
            "01: 0.0655\n",
            "02: 0.6544\n",
            "03: 0.0348\n",
            "04: 0.0336\n",
            "05: 0.0129\n",
            "06: 0.0059\n",
            "07: 0.0000\n",
            "08: 0.0000\n",
            "09: 0.0026\n",
            "10: 0.0037\n",
            "11: 0.0003\n",
            "12: 0.0093\n",
            "13: 0.3477\n",
            "14: 0.0000\n",
            "15: 0.0000\n",
            "16: 0.0000\n",
            "17: 0.0000\n",
            "18: 0.0000\n",
            "\n",
            "📊 Final mIoU with augmentation: 0.0982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}