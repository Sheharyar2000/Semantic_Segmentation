{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1Zd-Wk-1lKg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9939f92-ec2c-4ab5-caf1-c121b81987a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Paths to your zip files in Drive\n",
        "gta5_zip = \"/content/drive/MyDrive/Semantic_Segmentation/GTA5.zip\"\n",
        "cityscapes_zip = \"/content/drive/MyDrive/Semantic_Segmentation/Cityscapes.zip\"\n",
        "\n",
        "# Destination folders\n",
        "gta5_extract_path = \"/content/datasets/GTA5\"\n",
        "cityscapes_extract_path = \"/content/datasets/Cityscapes\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(gta5_extract_path, exist_ok=True)\n",
        "os.makedirs(cityscapes_extract_path, exist_ok=True)\n",
        "\n",
        "# Extract GTA5\n",
        "with zipfile.ZipFile(gta5_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(gta5_extract_path)\n",
        "\n",
        "# Extract Cityscapes\n",
        "with zipfile.ZipFile(cityscapes_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(cityscapes_extract_path)\n",
        "\n",
        "print(\"✅ GTA5 dataset extracted\")\n",
        "print(\"✅ Cityscapes dataset extracted\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf8k3k7nnoze",
        "outputId": "d124547b-058a-441e-c53d-699339117472"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GTA5 dataset extracted\n",
            "✅ Cityscapes dataset extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Fix Cityscapes structure\n",
        "base_city = \"/content/datasets/Cityscapes\"\n",
        "wrong_city_nested = os.path.join(base_city, \"Cityscapes\", \"Cityspaces\")\n",
        "\n",
        "if os.path.exists(wrong_city_nested):\n",
        "    for sub in [\"gtFine\", \"images\"]:\n",
        "        src = os.path.join(wrong_city_nested, sub)\n",
        "        dst = os.path.join(base_city, sub if sub == \"gtFine\" else \"leftImg8bit\")\n",
        "        shutil.move(src, dst)\n",
        "    shutil.rmtree(os.path.join(base_city, \"Cityscapes\"))\n",
        "    print(\"✅ Fixed Cityscapes structure\")\n",
        "\n",
        "# Fix GTA5 structure\n",
        "base_gta = \"/content/datasets/GTA5\"\n",
        "wrong_gta_nested = os.path.join(base_gta, \"GTA5\")\n",
        "\n",
        "if os.path.exists(wrong_gta_nested):\n",
        "    for sub in [\"images\", \"labels\"]:\n",
        "        shutil.move(os.path.join(wrong_gta_nested, sub), os.path.join(base_gta, sub))\n",
        "    shutil.rmtree(wrong_gta_nested)\n",
        "    print(\"✅ Fixed GTA5 structure\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9_IpXCGnou_",
        "outputId": "06cde15a-dedf-4682-b70e-60ff8283badb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fixed Cityscapes structure\n",
            "✅ Fixed GTA5 structure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as TF\n",
        "from PIL import Image\n",
        "\n",
        "# ✅ GTA5 → Cityscapes label remapping\n",
        "GTA5_TO_CITYSCAPES = {\n",
        "    7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 15: 5, 17: 6, 19: 7, 20: 8,\n",
        "    21: 9, 22: 10, 23: 11, 24: 12, 26: 13, 27: 14, 28: 15,\n",
        "    31: 16, 32: 17, 33: 18\n",
        "}\n",
        "\n",
        "class GTA5Dataset(Dataset):\n",
        "    def __init__(self, root, transform=None, target_transform=None, apply_color_jitter=False):\n",
        "        self.image_dir = os.path.join(root, \"images\")\n",
        "        self.label_dir = os.path.join(root, \"labels\")\n",
        "        self.images = sorted(os.listdir(self.image_dir))\n",
        "        self.labels = sorted(os.listdir(self.label_dir))\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.apply_color_jitter = apply_color_jitter\n",
        "        self.color_jitter = transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def encode_labels(self, mask):\n",
        "        remapped = np.full_like(mask, 255)\n",
        "        for gta_id, city_id in GTA5_TO_CITYSCAPES.items():\n",
        "            remapped[mask == gta_id] = city_id\n",
        "        return remapped\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.label_dir, self.labels[idx])\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path)\n",
        "\n",
        "        if self.apply_color_jitter and random.random() < 0.5:\n",
        "            img = self.color_jitter(img)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "            mask = self.encode_labels(mask.squeeze().numpy())\n",
        "            mask = torch.from_numpy(mask).long().unsqueeze(0)\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "class CityscapesDataset(Dataset):\n",
        "    def __init__(self, root, split='val', transform=None, target_transform=None):\n",
        "        self.image_dir = os.path.join(root, \"leftImg8bit\", split)\n",
        "        self.label_dir = os.path.join(root, \"gtFine\", split)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        for city in os.listdir(self.image_dir):\n",
        "            img_folder = os.path.join(self.image_dir, city)\n",
        "            label_folder = os.path.join(self.label_dir, city)\n",
        "\n",
        "            for file_name in os.listdir(img_folder):\n",
        "                if file_name.endswith(\"_leftImg8bit.png\"):\n",
        "                    base = file_name.replace(\"_leftImg8bit.png\", \"\")\n",
        "                    img_path = os.path.join(img_folder, file_name)\n",
        "                    label_path = os.path.join(label_folder, base + \"_gtFine_labelTrainIds.png\")\n",
        "\n",
        "                    if os.path.exists(label_path):\n",
        "                        self.images.append(img_path)\n",
        "                        self.labels.append(label_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        mask = Image.open(self.labels[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "\n",
        "        return img, mask\n"
      ],
      "metadata": {
        "id": "9E3fJmBopQkT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# ✅ Image/label transforms\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((720, 1280)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((720, 1280), interpolation=Image.NEAREST),\n",
        "    transforms.PILToTensor()\n",
        "])\n",
        "\n",
        "# ✅ Instantiate GTA5 training dataset (Color Jitter ON)\n",
        "gta5_dataset = GTA5Dataset(\n",
        "    root='/content/datasets/GTA5',\n",
        "    transform=image_transform,\n",
        "    target_transform=mask_transform,\n",
        "    apply_color_jitter=True  # ✅ Aug. 2: Enable Color Jitter only\n",
        ")\n",
        "\n",
        "# ✅ Instantiate Cityscapes validation dataset\n",
        "val_dataset = CityscapesDataset(\n",
        "    root='/content/datasets/Cityscapes',\n",
        "    split='val',\n",
        "    transform=image_transform,\n",
        "    target_transform=mask_transform\n",
        ")\n",
        "\n",
        "# ✅ Dataloaders\n",
        "train_loader = DataLoader(gta5_dataset, batch_size=2, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"✅ Train loader: {len(train_loader)} batches | Val loader: {len(val_loader)} batches\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luU1Q8tgp9Sn",
        "outputId": "29a5867b-8c07-41c4-ecc5-771bbcb25919"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train loader: 1250 batches | Val loader: 250 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfIFq4-Np_FO",
        "outputId": "362ae847-196f-48e7-973d-702452e5794c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLDL2024_project1'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 34 (delta 9), reused 3 (delta 3), pack-reused 15 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34/34), 11.29 KiB | 296.00 KiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "\n",
        "# Add the cloned repo to the system path\n",
        "sys.path.append(\"/content/MLDL2024_project1\")\n",
        "\n",
        "# Import BiSeNet\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "\n",
        "# Initialize BiSeNet for 19 classes and move to CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18').to(device)\n",
        "\n",
        "print(\"✅ BiSeNet with ResNet18 initialized and moved to\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVThtfGEqB23",
        "outputId": "e4a33bbb-9125-4f77-df09-58cf93f176cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 197MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:00<00:00, 225MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ BiSeNet with ResNet18 initialized and moved to cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "# Loss: CrossEntropy with ignore_index for void class\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "# Optimizer: SGD with momentum and weight decay\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# AMP Scaler for mixed precision training\n",
        "scaler = GradScaler()\n",
        "\n",
        "print(\"✅ Loss, optimizer, and AMP scaler initialized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5boV_yLcqGWf",
        "outputId": "6196c69b-0506-46cc-b269-15c590aaf7c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loss, optimizer, and AMP scaler initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "# ✅ Training config\n",
        "epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "save_path = \"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_colorjitter.pth\"\n",
        "\n",
        "print(\"🟢 Starting BiSeNet training with Color Jitter Augmentation...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", leave=False)\n",
        "\n",
        "    for images, masks in loop:\n",
        "        images = images.to(device)\n",
        "        masks = masks.squeeze(1).long().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            output, aux1, aux2 = model(images)\n",
        "            loss1 = criterion(output, masks)\n",
        "            loss2 = criterion(aux1, masks)\n",
        "            loss3 = criterion(aux2, masks)\n",
        "            loss = loss1 + 0.4 * (loss2 + loss3)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(train_loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # ✅ Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_imgs, val_masks in val_loader:\n",
        "            val_imgs = val_imgs.to(device)\n",
        "            val_masks = val_masks.squeeze(1).long().to(device)\n",
        "\n",
        "            with autocast():\n",
        "                val_out = model(val_imgs)\n",
        "                val_loss_batch = nn.CrossEntropyLoss(ignore_index=255)(val_out, val_masks)\n",
        "\n",
        "            val_loss += val_loss_batch.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"💾 Best model saved at epoch {epoch+1} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # ✅ Memory cleanup\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    mem_free = torch.cuda.mem_get_info()[0] / (1024 ** 3)\n",
        "\n",
        "    print(f\"✅ Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Free GPU: {mem_free:.2f} GB\")\n",
        "\n",
        "print(\"🏁 Augmented training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PyYRDn7qHoX",
        "outputId": "11ac1cf2-f6dd-46fb-abe8-7dd876eb4bd2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟢 Starting BiSeNet training with Color Jitter Augmentation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Best model saved at epoch 1 | Val Loss: 3.2385\n",
            "✅ Epoch 1 | Train Loss: 1.2565 | Val Loss: 3.2385 | Free GPU: 21.08 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 2 | Train Loss: 0.8799 | Val Loss: 3.3014 | Free GPU: 21.04 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 3 | Train Loss: 0.7332 | Val Loss: 3.7343 | Free GPU: 21.12 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Best model saved at epoch 4 | Val Loss: 2.8423\n",
            "✅ Epoch 4 | Train Loss: 0.6637 | Val Loss: 2.8423 | Free GPU: 21.07 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 5 | Train Loss: 0.6279 | Val Loss: 4.5020 | Free GPU: 21.09 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 6 | Train Loss: 0.5667 | Val Loss: 3.4748 | Free GPU: 20.93 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 7 | Train Loss: 0.5370 | Val Loss: 3.9209 | Free GPU: 20.93 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Best model saved at epoch 8 | Val Loss: 2.5342\n",
            "✅ Epoch 8 | Train Loss: 0.5628 | Val Loss: 2.5342 | Free GPU: 21.10 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 9 | Train Loss: 0.4876 | Val Loss: 3.4913 | Free GPU: 20.97 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 10 | Train Loss: 0.4609 | Val Loss: 4.9356 | Free GPU: 21.10 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Best model saved at epoch 11 | Val Loss: 2.3420\n",
            "✅ Epoch 11 | Train Loss: 0.4419 | Val Loss: 2.3420 | Free GPU: 20.98 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 12 | Train Loss: 0.4318 | Val Loss: 3.9413 | Free GPU: 20.89 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 13 | Train Loss: 0.4068 | Val Loss: 4.0537 | Free GPU: 21.04 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 14 | Train Loss: 0.4094 | Val Loss: 4.8332 | Free GPU: 20.91 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 15 | Train Loss: 0.3760 | Val Loss: 5.8574 | Free GPU: 21.15 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 16 | Train Loss: 0.3592 | Val Loss: 5.0078 | Free GPU: 21.07 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 17 | Train Loss: 0.3446 | Val Loss: 4.4977 | Free GPU: 20.94 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 18 | Train Loss: 0.3478 | Val Loss: 4.5668 | Free GPU: 21.09 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 19 | Train Loss: 0.3242 | Val Loss: 4.5351 | Free GPU: 20.93 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 20 | Train Loss: 0.3243 | Val Loss: 4.1521 | Free GPU: 21.00 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 21 | Train Loss: 0.3125 | Val Loss: 3.7400 | Free GPU: 21.02 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 22 | Train Loss: 0.3057 | Val Loss: 4.5348 | Free GPU: 20.86 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 23 | Train Loss: 0.3134 | Val Loss: 4.2985 | Free GPU: 20.87 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 24 | Train Loss: 0.2888 | Val Loss: 4.7729 | Free GPU: 21.04 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 25 | Train Loss: 0.2831 | Val Loss: 4.7002 | Free GPU: 21.06 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 26 | Train Loss: 0.2764 | Val Loss: 4.2991 | Free GPU: 20.76 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 27 | Train Loss: 0.2750 | Val Loss: 4.4466 | Free GPU: 21.00 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 28 | Train Loss: 0.2654 | Val Loss: 4.3825 | Free GPU: 20.96 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 29 | Train Loss: 0.2673 | Val Loss: 4.4992 | Free GPU: 21.09 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 30 | Train Loss: 0.2594 | Val Loss: 4.4752 | Free GPU: 20.98 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 31 | Train Loss: 0.2533 | Val Loss: 4.7305 | Free GPU: 21.08 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 32 | Train Loss: 0.2446 | Val Loss: 3.9350 | Free GPU: 21.02 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 33 | Train Loss: 0.2462 | Val Loss: 5.1452 | Free GPU: 21.00 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 34 | Train Loss: 0.4060 | Val Loss: 3.5457 | Free GPU: 20.95 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 35 | Train Loss: 0.3130 | Val Loss: 4.4856 | Free GPU: 21.11 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 36 | Train Loss: 0.2653 | Val Loss: 4.3501 | Free GPU: 20.98 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 37 | Train Loss: 0.2445 | Val Loss: 4.3293 | Free GPU: 21.05 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 38 | Train Loss: 0.2382 | Val Loss: 4.3667 | Free GPU: 21.05 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 39 | Train Loss: 0.2305 | Val Loss: 3.8642 | Free GPU: 21.03 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 40 | Train Loss: 0.2256 | Val Loss: 4.5995 | Free GPU: 20.98 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 41 | Train Loss: 0.2345 | Val Loss: 4.2743 | Free GPU: 21.02 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 42 | Train Loss: 0.2226 | Val Loss: 4.4451 | Free GPU: 21.14 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 43 | Train Loss: 0.2224 | Val Loss: 4.1772 | Free GPU: 21.04 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 44 | Train Loss: 0.2228 | Val Loss: 4.3787 | Free GPU: 21.13 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 45 | Train Loss: 0.2136 | Val Loss: 4.2970 | Free GPU: 21.09 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 46 | Train Loss: 0.2120 | Val Loss: 4.3388 | Free GPU: 21.12 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 47 | Train Loss: 0.2229 | Val Loss: 4.3928 | Free GPU: 21.13 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 48 | Train Loss: 0.2147 | Val Loss: 4.9023 | Free GPU: 21.02 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 49 | Train Loss: 0.2135 | Val Loss: 4.8388 | Free GPU: 21.15 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 50 | Train Loss: 0.2095 | Val Loss: 4.7064 | Free GPU: 21.17 GB\n",
            "🏁 Augmented training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model"
      ],
      "metadata": {
        "id": "ktmhCu_v8SGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save after training (if not already saved inside loop)\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_aug2.pth\")\n",
        "print(\"✅ Model saved to Google Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erwDvxTm8UF6",
        "outputId": "56ff6165-321e-4f34-b198-adc2218c8a86"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved to Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating mIoU"
      ],
      "metadata": {
        "id": "xOn48ija8UrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Reload model\n",
        "model_aug2 = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "model_aug2.load_state_dict(torch.load(\"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_aug2.pth\"))\n",
        "model_aug2 = model_aug2.to('cuda')\n",
        "model_aug2.eval()\n",
        "\n",
        "# Validation mIoU\n",
        "def evaluate_miou(model, dataloader, num_classes=19):\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    iou_list = []\n",
        "    hist = torch.zeros(num_classes, num_classes).to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=\"🔍 Evaluating mIoU\"):\n",
        "            images = images.to('cuda')\n",
        "            labels = labels.squeeze(1).to('cuda')\n",
        "\n",
        "            preds = model(images)\n",
        "            preds = torch.argmax(preds, dim=1)\n",
        "\n",
        "            for p, t in zip(preds, labels):\n",
        "                hist += torch.bincount(\n",
        "                    num_classes * t.flatten() + p.flatten(),\n",
        "                    minlength=num_classes ** 2\n",
        "                ).reshape(num_classes, num_classes)\n",
        "\n",
        "    iou = hist.diag() / (hist.sum(1) + hist.sum(0) - hist.diag() + 1e-6)\n",
        "    for i, val in enumerate(iou):\n",
        "        print(f\"{i:02d}: {val:.4f}\")\n",
        "    print(f\"\\n📊 Final mIoU with augmentation: {iou.mean():.4f}\")\n",
        "\n",
        "evaluate_miou(model_aug2, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3fIijki8Y1Q",
        "outputId": "4bb81815-341b-411b-ef16-ac83db9c2cd2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Evaluating mIoU: 100%|██████████| 250/250 [00:35<00:00,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00: 0.1207\n",
            "01: 0.1563\n",
            "02: 0.5140\n",
            "03: 0.0436\n",
            "04: 0.0708\n",
            "05: 0.0137\n",
            "06: 0.0043\n",
            "07: 0.0012\n",
            "08: 0.0002\n",
            "09: 0.0047\n",
            "10: 0.0042\n",
            "11: 0.0000\n",
            "12: 0.2259\n",
            "13: 0.2542\n",
            "14: 0.0000\n",
            "15: 0.0000\n",
            "16: 0.0000\n",
            "17: 0.0000\n",
            "18: 0.0000\n",
            "\n",
            "📊 Final mIoU with augmentation: 0.0744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}