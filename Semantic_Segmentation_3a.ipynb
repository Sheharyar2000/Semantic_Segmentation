{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwBYeDrmWArn",
        "outputId": "520b51c9-2edd-49bd-e898-590cbe4d0b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Google Drive paths to your ZIP files\n",
        "gta5_zip = \"/content/drive/MyDrive/Semantic_Segmentation/GTA5.zip\"\n",
        "cityscapes_zip = \"/content/drive/MyDrive/Semantic_Segmentation/Cityscapes.zip\"\n",
        "\n",
        "# Target directories in Colab local storage\n",
        "gta5_extract_to = \"/content/datasets/GTA5\"\n",
        "cityscapes_extract_to = \"/content/datasets/Cityscapes\"\n",
        "\n",
        "# Unzip GTA5\n",
        "if not os.path.exists(gta5_extract_to):\n",
        "    with zipfile.ZipFile(gta5_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(gta5_extract_to)\n",
        "    print(\"âœ… GTA5 dataset extracted\")\n",
        "\n",
        "# Unzip Cityscapes\n",
        "if not os.path.exists(cityscapes_extract_to):\n",
        "    with zipfile.ZipFile(cityscapes_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(cityscapes_extract_to)\n",
        "    print(\"âœ… Cityscapes dataset extracted\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP9NNXROY0cB",
        "outputId": "ca3a9f6f-c584-44ce-9ee1-2a825f4bac1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GTA5 dataset extracted\n",
            "âœ… Cityscapes dataset extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# âœ… GTA5: move inner images & labels out, delete nested folder\n",
        "gta5_base = \"/content/datasets/GTA5\"\n",
        "nested_gta5 = os.path.join(gta5_base, \"GTA5\")\n",
        "\n",
        "if os.path.exists(os.path.join(nested_gta5, \"images\")):\n",
        "    shutil.move(os.path.join(nested_gta5, \"images\"), gta5_base)\n",
        "    shutil.move(os.path.join(nested_gta5, \"labels\"), gta5_base)\n",
        "    shutil.rmtree(nested_gta5)\n",
        "    print(\"âœ… Fixed GTA5 folder structure.\")\n",
        "\n",
        "# âœ… Cityscapes: fix double nesting and spelling error (Cityspaces â†’ leftImg8bit)\n",
        "city_base = \"/content/datasets/Cityscapes\"\n",
        "nested_city = os.path.join(city_base, \"Cityscapes\", \"Cityspaces\")\n",
        "\n",
        "if os.path.exists(nested_city):\n",
        "    shutil.move(os.path.join(nested_city, \"gtFine\"), city_base)\n",
        "    shutil.move(os.path.join(nested_city, \"images\"), os.path.join(city_base, \"leftImg8bit\"))\n",
        "    shutil.rmtree(os.path.join(city_base, \"Cityscapes\"))\n",
        "    print(\"âœ… Fixed Cityscapes folder structure.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1JMhNi_aqoN",
        "outputId": "09530626-6803-484b-f55f-273b860b6564"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Fixed GTA5 folder structure.\n",
            "âœ… Fixed Cityscapes folder structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "# âœ… GTA5 â†’ Cityscapes TrainID Mapping (19 classes)\n",
        "GTA5_to_Cityscapes = {\n",
        "    7: 0,     # road\n",
        "    8: 1,     # sidewalk\n",
        "    11: 2,    # building\n",
        "    12: 3,    # wall\n",
        "    13: 4,    # fence\n",
        "    17: 5,    # pole\n",
        "    19: 6,    # traffic light\n",
        "    20: 7,    # traffic sign\n",
        "    21: 8,    # vegetation\n",
        "    22: 9,    # terrain\n",
        "    23: 10,   # sky\n",
        "    24: 11,   # person\n",
        "    25: 12,   # rider\n",
        "    26: 13,   # car\n",
        "    27: 14,   # truck\n",
        "    28: 15,   # bus\n",
        "    31: 16,   # train\n",
        "    32: 17,   # motorcycle\n",
        "    33: 18    # bicycle\n",
        "}\n",
        "\n",
        "class GTA5Dataset(Dataset):\n",
        "    def __init__(self, root, transform=None, target_transform=None):\n",
        "        self.root = root\n",
        "        self.images_dir = os.path.join(root, 'images')\n",
        "        self.labels_dir = os.path.join(root, 'labels')\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.images = sorted(os.listdir(self.images_dir))\n",
        "        self.labels = sorted(os.listdir(self.labels_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.images_dir, self.images[idx])\n",
        "        label_path = os.path.join(self.labels_dir, self.labels[idx])\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = Image.open(label_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "            label = self.remap_labels(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def remap_labels(self, mask_tensor):\n",
        "        # Convert to numpy\n",
        "        mask_np = mask_tensor.squeeze().numpy()\n",
        "        remapped = np.full_like(mask_np, 255)  # set default to ignore index\n",
        "\n",
        "        for gta_id, city_id in GTA5_to_Cityscapes.items():\n",
        "            remapped[mask_np == gta_id] = city_id\n",
        "\n",
        "        # Return as tensor (no channel)\n",
        "        return torch.from_numpy(remapped).long()\n",
        "\n",
        "print(\"âœ… GTA5Dataset class defined with correct label remapping.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKHA_x4JfoAk",
        "outputId": "70831111-f70f-4a86-e9cd-4a19398a72e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GTA5Dataset class defined with correct label remapping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class CityscapesDataset(Dataset):\n",
        "    def __init__(self, split='val', transform=None, target_transform=None):\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.images = []\n",
        "        self.masks = []\n",
        "\n",
        "        images_base = \"/content/datasets/Cityscapes/leftImg8bit\"\n",
        "        masks_base = \"/content/datasets/Cityscapes/gtFine\"\n",
        "\n",
        "        cities_path = os.path.join(images_base, split)\n",
        "        for city in os.listdir(cities_path):\n",
        "            img_dir = os.path.join(cities_path, city)\n",
        "            mask_dir = os.path.join(masks_base, split, city)\n",
        "\n",
        "            for file_name in os.listdir(img_dir):\n",
        "                if file_name.endswith(\"_leftImg8bit.png\"):\n",
        "                    base = file_name.replace(\"_leftImg8bit.png\", \"\")\n",
        "                    img_path = os.path.join(img_dir, file_name)\n",
        "                    mask_path = os.path.join(mask_dir, base + \"_gtFine_labelTrainIds.png\")\n",
        "                    if os.path.exists(mask_path):\n",
        "                        self.images.append(img_path)\n",
        "                        self.masks.append(mask_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        mask = Image.open(self.masks[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "print(\"âœ… CityscapesDataset class defined for validation.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PL00twUgVYg",
        "outputId": "12282c17-b31b-48fa-8ef0-8ed0ea3ee053"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… CityscapesDataset class defined for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from PIL import Image\n",
        "\n",
        "# âœ… Standard image transform (GTA5 and Cityscapes)\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 1024), interpolation=InterpolationMode.BILINEAR),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# âœ… Mask transform (nearest neighbor resize only)\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 1024), interpolation=Image.NEAREST),\n",
        "    transforms.PILToTensor()  # Keeps shape [1, H, W] and type uint8\n",
        "])\n",
        "\n",
        "# âœ… Instantiate datasets\n",
        "gta5_dataset = GTA5Dataset(\n",
        "    root='/content/datasets/GTA5',\n",
        "    transform=image_transform,\n",
        "    target_transform=mask_transform\n",
        ")\n",
        "\n",
        "cityscapes_val_dataset = CityscapesDataset(\n",
        "    split='val',\n",
        "    transform=image_transform,\n",
        "    target_transform=mask_transform\n",
        ")\n",
        "\n",
        "# âœ… Create dataloaders\n",
        "train_loader = DataLoader(gta5_dataset, batch_size=2, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(cityscapes_val_dataset, batch_size=2, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"âœ… GTA5 dataset size: {len(gta5_dataset)} | Cityscapes val size: {len(cityscapes_val_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rC_nNwMg3hj",
        "outputId": "ee106ef1-2acf-494b-e4cd-edf38372537d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GTA5 dataset size: 2500 | Cityscapes val size: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Clone the official project repo\n",
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk5VQqKVhn9Q",
        "outputId": "37e6750d-57b6-45a0-d4e2-85c98c8b4d81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLDL2024_project1'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 34 (delta 9), reused 3 (delta 3), pack-reused 15 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34/34), 11.29 KiB | 11.29 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/MLDL2024_project1\")\n",
        "\n",
        "# Now try importing BiSeNet\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "print(\"âœ… BiSeNet import successful.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_caANDXiBJC",
        "outputId": "43be455b-65dd-47b8-8446-777f503d9703"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… BiSeNet import successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "\n",
        "# âœ… Initialize BiSeNet with ResNet18 backbone\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "model = model.to('cuda')  # Move to GPU if available\n",
        "\n",
        "print(\"âœ… BiSeNet model initialized and moved to GPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fbhWld_jf2c",
        "outputId": "5caa790e-910f-4eea-dea4-330ca45bde24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 225MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171M/171M [00:00<00:00, 231MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… BiSeNet model initialized and moved to GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "# âœ… Loss function (ignore class 255 in targets)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "# âœ… Optimizer (SGD)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# âœ… Mixed precision scaler for AMP\n",
        "scaler = GradScaler()\n",
        "\n",
        "print(\"âœ… Loss function, optimizer, and mixed precision scaler initialized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOBIwazajLYy",
        "outputId": "ef3f6c54-c0e1-4ed2-c415-90e6157a4ae4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loss function, optimizer, and mixed precision scaler initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import os\n",
        "\n",
        "# âœ… Training configuration\n",
        "epochs = 50\n",
        "best_val_loss = float(\"inf\")\n",
        "save_path = \"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta2city_best.pth\"\n",
        "\n",
        "print(\"ðŸŸ¢ Starting BiSeNet training (GTA5 â†’ Cityscapes)...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    loop = tqdm(train_loader, total=len(train_loader), desc=f\"Epoch [{epoch+1}/{epochs}]\", leave=False)\n",
        "\n",
        "    for images, targets in loop:\n",
        "        images = images.to('cuda')\n",
        "        targets = targets.squeeze(1).long().to('cuda')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            output, aux1, aux2 = model(images)\n",
        "            loss1 = criterion(output, targets)\n",
        "            loss2 = criterion(aux1, targets)\n",
        "            loss3 = criterion(aux2, targets)\n",
        "            loss = loss1 + 0.4 * (loss2 + loss3)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # âœ… Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_imgs, val_masks in val_loader:\n",
        "            val_imgs = val_imgs.to('cuda')\n",
        "            val_masks = val_masks.squeeze(1).long().to('cuda')\n",
        "\n",
        "            with autocast():\n",
        "                val_output = model(val_imgs)\n",
        "                val_loss_batch = criterion(val_output, val_masks)\n",
        "\n",
        "            val_loss += val_loss_batch.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    # âœ… Save best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"ðŸ’¾ Best model saved at epoch {epoch+1} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # âœ… Memory cleanup\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    mem_free = torch.cuda.mem_get_info()[0] / (1024 ** 3)\n",
        "\n",
        "    print(f\"âœ… Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Free GPU: {mem_free:.2f} GB\")\n",
        "\n",
        "print(\"ðŸ BiSeNet training (Step 3a) complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fovk_skXkagz",
        "outputId": "63b67ee5-2606-44c4-aeba-e81db113bf61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŸ¢ Starting BiSeNet training (GTA5 â†’ Cityscapes)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¾ Best model saved at epoch 1 | Val Loss: 2.2858\n",
            "âœ… Epoch 1 | Train Loss: 1.1986 | Val Loss: 2.2858 | Free GPU: 21.41 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¾ Best model saved at epoch 2 | Val Loss: 1.0293\n",
            "âœ… Epoch 2 | Train Loss: 0.8446 | Val Loss: 1.0293 | Free GPU: 21.43 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 3 | Train Loss: 0.7361 | Val Loss: 2.6784 | Free GPU: 21.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 4 | Train Loss: 0.6736 | Val Loss: 2.2253 | Free GPU: 21.37 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 5 | Train Loss: 0.6152 | Val Loss: 1.2436 | Free GPU: 21.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 6 | Train Loss: 0.5925 | Val Loss: 1.8468 | Free GPU: 21.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 7 | Train Loss: 0.5271 | Val Loss: 2.4453 | Free GPU: 21.31 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 8 | Train Loss: 0.4941 | Val Loss: 3.3287 | Free GPU: 21.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 9 | Train Loss: 0.4826 | Val Loss: 2.0138 | Free GPU: 21.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 10 | Train Loss: 0.4647 | Val Loss: 3.2641 | Free GPU: 21.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 11 | Train Loss: 0.4221 | Val Loss: 3.5666 | Free GPU: 21.24 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 12 | Train Loss: 0.4101 | Val Loss: 5.7119 | Free GPU: 21.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 13 | Train Loss: 0.3968 | Val Loss: 3.6393 | Free GPU: 21.29 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 14 | Train Loss: 0.3803 | Val Loss: 3.9428 | Free GPU: 21.39 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 15 | Train Loss: 0.3591 | Val Loss: 3.9348 | Free GPU: 21.34 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 16 | Train Loss: 0.3495 | Val Loss: 4.1406 | Free GPU: 21.37 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 17 | Train Loss: 0.3409 | Val Loss: 3.2966 | Free GPU: 21.35 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 18 | Train Loss: 0.3197 | Val Loss: 3.2982 | Free GPU: 21.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 19 | Train Loss: 0.3157 | Val Loss: 2.8801 | Free GPU: 21.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 20 | Train Loss: 0.3080 | Val Loss: 3.1485 | Free GPU: 21.40 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 21 | Train Loss: 0.3491 | Val Loss: 2.6694 | Free GPU: 21.32 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 22 | Train Loss: 0.3038 | Val Loss: 3.8074 | Free GPU: 21.41 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 23 | Train Loss: 0.2926 | Val Loss: 2.9460 | Free GPU: 21.37 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 24 | Train Loss: 0.2809 | Val Loss: 4.0715 | Free GPU: 21.39 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 25 | Train Loss: 0.2750 | Val Loss: 2.9981 | Free GPU: 21.35 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 26 | Train Loss: 0.2907 | Val Loss: 4.2110 | Free GPU: 21.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 27 | Train Loss: 0.2902 | Val Loss: 6.6587 | Free GPU: 21.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 28 | Train Loss: 0.2746 | Val Loss: 4.1887 | Free GPU: 21.37 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 29 | Train Loss: 0.2597 | Val Loss: 3.7098 | Free GPU: 21.37 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 30 | Train Loss: 0.2541 | Val Loss: 3.2393 | Free GPU: 21.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 31 | Train Loss: 0.2496 | Val Loss: 4.3402 | Free GPU: 21.35 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 32 | Train Loss: 0.2490 | Val Loss: 3.2749 | Free GPU: 21.23 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 33 | Train Loss: 0.2466 | Val Loss: 2.6625 | Free GPU: 21.29 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 34 | Train Loss: 0.2409 | Val Loss: 2.3207 | Free GPU: 21.35 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 35 | Train Loss: 0.2359 | Val Loss: 3.0595 | Free GPU: 21.34 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 36 | Train Loss: 0.2315 | Val Loss: 3.0488 | Free GPU: 21.29 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 37 | Train Loss: 0.2292 | Val Loss: 3.6287 | Free GPU: 21.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 38 | Train Loss: 0.2305 | Val Loss: 3.8360 | Free GPU: 21.37 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 39 | Train Loss: 0.2254 | Val Loss: 3.4550 | Free GPU: 21.25 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 40 | Train Loss: 0.3445 | Val Loss: 2.5358 | Free GPU: 21.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 41 | Train Loss: 0.3138 | Val Loss: 2.8711 | Free GPU: 21.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 42 | Train Loss: 0.2609 | Val Loss: 2.9445 | Free GPU: 21.35 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 43 | Train Loss: 0.2337 | Val Loss: 3.0068 | Free GPU: 21.37 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 44 | Train Loss: 0.2260 | Val Loss: 3.9424 | Free GPU: 21.40 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 45 | Train Loss: 0.2202 | Val Loss: 2.6222 | Free GPU: 21.34 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 46 | Train Loss: 0.2170 | Val Loss: 3.9367 | Free GPU: 21.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 47 | Train Loss: 0.2149 | Val Loss: 3.0132 | Free GPU: 21.39 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 48 | Train Loss: 0.2157 | Val Loss: 1.3386 | Free GPU: 21.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 49 | Train Loss: 0.2104 | Val Loss: 2.2574 | Free GPU: 21.45 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 50 | Train Loss: 0.2147 | Val Loss: 3.1058 | Free GPU: 21.33 GB\n",
            "ðŸ BiSeNet training (Step 3a) complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Save final GTA5-trained model to Drive\n",
        "final_model_path = \"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_final.pth\"\n",
        "torch.save(model.state_dict(), final_model_path)\n",
        "print(f\"âœ… Model saved to: {final_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGorp-aWDw3D",
        "outputId": "d40ad6f0-99b0-454c-c677-aafbaf4f0539"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved to: /content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_final.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… Re-load BiSeNet model with ResNet18 backbone\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_final.pth\"))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# âœ… mIoU calculation setup\n",
        "num_classes = 19\n",
        "conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
        "\n",
        "def update_conf_matrix(pred, label, conf_matrix):\n",
        "    mask = (label >= 0) & (label < num_classes)\n",
        "    hist = np.bincount(\n",
        "        num_classes * label[mask].astype(int) + pred[mask].astype(int),\n",
        "        minlength=num_classes ** 2\n",
        "    ).reshape(num_classes, num_classes)\n",
        "    conf_matrix += hist\n",
        "    return conf_matrix\n",
        "\n",
        "# âœ… Iterate through Cityscapes val set\n",
        "with torch.no_grad():\n",
        "    for images, targets in tqdm(val_loader, desc=\"Evaluating mIoU\"):\n",
        "        images = images.to(device)\n",
        "        targets = targets.squeeze(1).cpu().numpy()\n",
        "\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        for pred, label in zip(preds, targets):\n",
        "            conf_matrix = update_conf_matrix(pred, label, conf_matrix)\n",
        "\n",
        "# âœ… Compute mIoU\n",
        "intersection = np.diag(conf_matrix)\n",
        "union = conf_matrix.sum(1) + conf_matrix.sum(0) - intersection\n",
        "iou = intersection / (union + 1e-10)\n",
        "miou = np.nanmean(iou)\n",
        "\n",
        "print(f\"ðŸ“Š Final mIoU (GTA5 â†’ Cityscapes): {miou:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsdWQ3SrGarc",
        "outputId": "64d7ab45-e0fc-4671-b9a9-2369bdc9a8ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating mIoU: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:30<00:00,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Final mIoU (GTA5 â†’ Cityscapes): 0.1697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# âœ… Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = 19\n",
        "class_names = [\n",
        "    'road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light', 'traffic sign',\n",
        "    'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle'\n",
        "]\n",
        "\n",
        "# âœ… Load model\n",
        "model = BiSeNet(num_classes=num_classes, context_path='resnet18')\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Semantic_Segmentation/bisenet_gta5_final.pth\"))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# âœ… Confusion matrix initialization\n",
        "conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
        "\n",
        "# âœ… Evaluation loop\n",
        "print(\"ðŸ” Computing per-class IoU...\")\n",
        "with torch.no_grad():\n",
        "    for images, targets in tqdm(val_loader):\n",
        "        images = images.to(device)\n",
        "        targets = targets.squeeze(1).cpu().numpy()\n",
        "\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "\n",
        "        for t, p in zip(targets, preds):\n",
        "            mask = (t != 255)\n",
        "            conf_matrix += confusion_matrix(\n",
        "                t[mask].flatten(),\n",
        "                p[mask].flatten(),\n",
        "                labels=np.arange(num_classes)\n",
        "            )\n",
        "\n",
        "# âœ… Compute per-class IoU\n",
        "intersection = np.diag(conf_matrix)\n",
        "union = conf_matrix.sum(1) + conf_matrix.sum(0) - intersection\n",
        "iou = intersection / np.maximum(union, 1)\n",
        "\n",
        "# âœ… Print formatted table row\n",
        "print(\"\\nðŸ“Š Table 3 â€” Per-class IoUs (GTA5 â†’ Cityscapes):\")\n",
        "print(f\"mIoU: {np.mean(iou):.4f}\")\n",
        "for cls_name, score in zip(class_names, iou):\n",
        "    print(f\"{cls_name:<15}: {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmkV-2Irq9w2",
        "outputId": "3c6eb38c-8989-4639-b7a3-7c6310d99e4c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Computing per-class IoU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:30<00:00,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Table 3 â€” Per-class IoUs (GTA5 â†’ Cityscapes):\n",
            "mIoU: 0.1697\n",
            "road           : 0.0744\n",
            "sidewalk       : 0.1029\n",
            "building       : 0.6755\n",
            "wall           : 0.1060\n",
            "fence          : 0.0510\n",
            "pole           : 0.1623\n",
            "traffic light  : 0.0390\n",
            "traffic sign   : 0.0391\n",
            "vegetation     : 0.6584\n",
            "terrain        : 0.0438\n",
            "sky            : 0.6856\n",
            "person         : 0.3097\n",
            "rider          : 0.0229\n",
            "car            : 0.1851\n",
            "truck          : 0.0284\n",
            "bus            : 0.0252\n",
            "train          : 0.0000\n",
            "motorcycle     : 0.0069\n",
            "bicycle        : 0.0087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}