{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND09KGGH0-As",
        "outputId": "43e00fbb-d0e2-491d-a755-21c2ba2f348c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Semantic_Segmentation/Cityscapes.zip'\n",
        "extract_path = '/content/datasets/Cityscapes'\n",
        "\n",
        "# Create destination directory\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"‚úÖ Cityscapes dataset extracted to:\", extract_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui0L32jW1oaw",
        "outputId": "f04f87e5-dbe3-4ebf-9cd9-d965303e0904"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cityscapes dataset extracted to: /content/datasets/Cityscapes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "nested_path = '/content/datasets/Cityscapes/Cityscapes/Cityspaces'\n",
        "target_path = '/content/datasets/Cityscapes'\n",
        "\n",
        "# Move folders to correct target location\n",
        "shutil.move(os.path.join(nested_path, 'gtFine'), os.path.join(target_path, 'gtFine'))\n",
        "shutil.move(os.path.join(nested_path, 'images'), os.path.join(target_path, 'leftImg8bit'))\n",
        "\n",
        "# Cleanup: remove wrongly nested folders\n",
        "shutil.rmtree('/content/datasets/Cityscapes/Cityscapes')\n",
        "\n",
        "print(\"‚úÖ Folder structure corrected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZjlmxFA2kTv",
        "outputId": "114c65c3-a5f0-463f-ae63-3a9267b231d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Folder structure corrected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "free_mem = torch.cuda.mem_get_info()[0] / (1024 ** 3)  # in GB\n",
        "total_mem = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)\n",
        "print(f\"‚úÖ GPU memory available: {free_mem:.2f} GB / {total_mem:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyNnJIkV2p63",
        "outputId": "87b328a1-59a9-4fa8-878a-3eb0c7e3e613"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU memory available: 14.64 GB / 14.74 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# ‚úÖ Adjusted paths\n",
        "root_dir = \"/content/datasets/Cityscapes\"\n",
        "images_base = os.path.join(root_dir, \"leftImg8bit\")\n",
        "masks_base = os.path.join(root_dir, \"gtFine\")\n",
        "\n",
        "# ‚úÖ Custom Cityscapes Dataset\n",
        "class CityscapesDataset(Dataset):\n",
        "    def __init__(self, split='train', transform=None, target_transform=None):\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.images = []\n",
        "        self.masks = []\n",
        "\n",
        "        cities_path = os.path.join(images_base, split)\n",
        "        for city in os.listdir(cities_path):\n",
        "            img_dir = os.path.join(cities_path, city)\n",
        "            mask_dir = os.path.join(masks_base, split, city)\n",
        "\n",
        "            for file_name in os.listdir(img_dir):\n",
        "                if file_name.endswith(\"_leftImg8bit.png\"):\n",
        "                    base = file_name.replace(\"_leftImg8bit.png\", \"\")\n",
        "                    img_path = os.path.join(img_dir, file_name)\n",
        "                    mask_path = os.path.join(mask_dir, base + \"_gtFine_labelTrainIds.png\")\n",
        "                    if os.path.exists(mask_path):  # validate existence\n",
        "                        self.images.append(img_path)\n",
        "                        self.masks.append(mask_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.images[idx]).convert('RGB')\n",
        "        mask = Image.open(self.masks[idx])  # labelTrainIds already applied\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "# ‚úÖ Transformations (1024x512 as required)\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 1024)),  # height, width\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 1024), interpolation=Image.NEAREST),\n",
        "    transforms.PILToTensor(),\n",
        "    transforms.Lambda(lambda x: x.long())  # ‚úÖ FIX: ensure target is LongTensor\n",
        "])\n",
        "\n",
        "# ‚úÖ Initialize datasets\n",
        "train_dataset = CityscapesDataset(split='train', transform=image_transform, target_transform=mask_transform)\n",
        "val_dataset = CityscapesDataset(split='val', transform=image_transform, target_transform=mask_transform)\n",
        "\n",
        "# ‚úÖ DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"‚úÖ Dataset loaded: {len(train_dataset)} training samples, {len(val_dataset)} validation samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4QfBuRa24gh",
        "outputId": "a7076b0a-bcf6-4b44-f712-9bfb59e1aabf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset loaded: 1572 training samples, 500 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js1wvW7q3HOp",
        "outputId": "48cc3996-3d97-4a59-d596-b9deb0829c1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLDL2024_project1'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 34 (delta 9), reused 3 (delta 3), pack-reused 15 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34/34), 11.29 KiB | 11.29 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/MLDL2024_project1')\n",
        "\n",
        "from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "import torch\n",
        "\n",
        "# ‚úÖ Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"‚úÖ Using device:\", device)\n",
        "\n",
        "# ‚úÖ Pretrained model path\n",
        "pretrain_model_path = '/content/drive/MyDrive/Semantic_Segmentation/deeplab_resnet_pretrained_imagenet.pth'\n",
        "\n",
        "# ‚úÖ Load model with reduced memory (half precision)\n",
        "model = get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path=pretrain_model_path)\n",
        "model = model.to(device)\n",
        "print(\"‚úÖ Model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXR1AS3w3K6S",
        "outputId": "26572c6c-74a9-44ea-b2dd-b4079bdb841a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using device: cuda\n",
            "Deeplab pretraining loading...\n",
            "‚úÖ Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "free_mem = torch.cuda.mem_get_info()[0] / (1024 ** 3)\n",
        "total_mem = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)\n",
        "\n",
        "print(f\"üîç GPU Memory: {free_mem:.2f} GB free / {total_mem:.2f} GB total\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7s1qauo3RxD",
        "outputId": "adb041f8-215d-42fe-aca7-36bb0160cfed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç GPU Memory: 14.47 GB free / 14.74 GB total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# Mixed precision scaler\n",
        "scaler = GradScaler(device='cuda')\n",
        "\n",
        "print(\"‚úÖ Loss, optimizer, and mixed-precision scaler initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mG8JrK23cWz",
        "outputId": "f07f0253-9139-44a9-8018-a09c55c7fe86"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loss, optimizer, and mixed-precision scaler initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Sanity check for label dtype and values\n",
        "img, mask = train_dataset[0]\n",
        "print(\"Image dtype:\", img.dtype, \"| Shape:\", img.shape)\n",
        "print(\"Mask dtype:\", mask.dtype, \"| Shape:\", mask.shape)\n",
        "print(\"Unique label values:\", torch.unique(mask))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fYwpQkO3gF8",
        "outputId": "315ee278-1cb6-4cae-d57e-16dd5294b0f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image dtype: torch.float32 | Shape: torch.Size([3, 512, 1024])\n",
            "Mask dtype: torch.int64 | Shape: torch.Size([1, 512, 1024])\n",
            "Unique label values: tensor([  0,   1,   2,   5,   7,  10,  11,  12,  13,  18, 255])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Check"
      ],
      "metadata": {
        "id": "sRXiIyJuCII3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import gc\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# Set number of epochs (change to 50 after debugging)\n",
        "num_epochs = 5\n",
        "\n",
        "print(\"üü¢ Starting training...\")\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n",
        "\n",
        "    for images, targets in loop:\n",
        "        # ‚úÖ Move tensors to GPU\n",
        "        images = images.to(device)\n",
        "        targets = targets.squeeze(1).long().to(device)  # remove channel dim, ensure long type\n",
        "\n",
        "        # ‚úÖ Zero out gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ‚úÖ Forward + backward with mixed precision\n",
        "        with autocast(device_type='cuda'):\n",
        "            outputs, _, _ = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    # ‚úÖ GPU cleanup + memory stats\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    free_mem = torch.cuda.mem_get_info()[0] / (1024 ** 3)\n",
        "    print(f\"‚úÖ Epoch {epoch+1} finished | Loss: {avg_loss:.4f} | Free GPU: {free_mem:.2f} GB\")\n",
        "\n",
        "print(\"üèÅ Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oYq8kIu3yjl",
        "outputId": "e485a9cd-58fb-47d1-9f2d-cce912341de7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üü¢ Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 1 finished | Loss: 1.2620 | Free GPU: 13.53 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 2 finished | Loss: 0.7476 | Free GPU: 13.49 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 3 finished | Loss: 0.6286 | Free GPU: 13.45 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 4 finished | Loss: 0.5534 | Free GPU: 13.50 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 5 finished | Loss: 0.5059 | Free GPU: 13.36 GB\n",
            "üèÅ Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "AJFrymeiCK-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.amp import autocast\n",
        "import torch.nn.functional as F\n",
        "import gc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# üß™ Simple mIoU Calculation\n",
        "def compute_mIoU(preds, labels, num_classes=19, ignore_index=255):\n",
        "    preds = preds.cpu().numpy().flatten()\n",
        "    labels = labels.cpu().numpy().flatten()\n",
        "\n",
        "    # Filter out ignore_index\n",
        "    mask = labels != ignore_index\n",
        "    preds = preds[mask]\n",
        "    labels = labels[mask]\n",
        "\n",
        "    conf_matrix = confusion_matrix(labels, preds, labels=list(range(num_classes)))\n",
        "    intersection = np.diag(conf_matrix)\n",
        "    union = conf_matrix.sum(1) + conf_matrix.sum(0) - np.diag(conf_matrix)\n",
        "\n",
        "    IoU = intersection / np.maximum(union, 1)\n",
        "    mIoU = np.mean(IoU)\n",
        "    return mIoU\n",
        "\n",
        "# üîÅ Config\n",
        "num_epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "save_path = '/content/best_deeplabv2_cityscapes.pth'\n",
        "\n",
        "print(\"üü¢ Starting full training...\")\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_mious = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n",
        "\n",
        "    for images, targets in loop:\n",
        "        images = images.to(device)\n",
        "        targets = targets.long().squeeze(1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast('cuda'):\n",
        "            outputs, _, _ = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        loop.set_postfix(train_loss=loss.item())\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # üß™ VALIDATION\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    miou_total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_imgs, val_masks in val_loader:\n",
        "            val_imgs = val_imgs.to(device)\n",
        "            val_masks = val_masks.long().squeeze(1).to(device)\n",
        "\n",
        "            with autocast(device_type='cuda'):\n",
        "                val_outputs = model(val_imgs)\n",
        "                loss = criterion(val_outputs, val_masks)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(val_outputs, dim=1)\n",
        "                miou = compute_mIoU(preds, val_masks)\n",
        "                miou_total += miou\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    avg_miou = miou_total / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_mious.append(avg_miou)\n",
        "\n",
        "    # üíæ Save best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"üíæ Best model saved at epoch {epoch+1} | Val Loss: {avg_val_loss:.4f} | mIoU: {avg_miou:.4f}\")\n",
        "\n",
        "    # ‚ôªÔ∏è Clean up\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    mem_free = torch.cuda.mem_get_info()[0] / (1024 ** 3)\n",
        "\n",
        "    print(f\"‚úÖ Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | mIoU: {avg_miou:.4f} | Free GPU: {mem_free:.2f} GB\")\n",
        "\n",
        "print(\"üèÅ Training complete.\")\n",
        "print(f\"üìâ Best Validation Loss: {best_val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZmQdAwXCMiB",
        "outputId": "b4cda67d-ae34-4f1d-daff-4a0b87ad173d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üü¢ Starting full training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Best model saved at epoch 1 | Val Loss: 0.3657 | mIoU: 0.3353\n",
            "‚úÖ Epoch 1 | Train Loss: 0.4809 | Val Loss: 0.3657 | mIoU: 0.3353 | Free GPU: 13.41 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Best model saved at epoch 2 | Val Loss: 0.2813 | mIoU: 0.3683\n",
            "‚úÖ Epoch 2 | Train Loss: 0.2433 | Val Loss: 0.2813 | mIoU: 0.3683 | Free GPU: 13.52 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Best model saved at epoch 3 | Val Loss: 0.2519 | mIoU: 0.3945\n",
            "‚úÖ Epoch 3 | Train Loss: 0.1852 | Val Loss: 0.2519 | mIoU: 0.3945 | Free GPU: 13.49 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Best model saved at epoch 4 | Val Loss: 0.2318 | mIoU: 0.4076\n",
            "‚úÖ Epoch 4 | Train Loss: 0.1553 | Val Loss: 0.2318 | mIoU: 0.4076 | Free GPU: 13.36 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Best model saved at epoch 5 | Val Loss: 0.2272 | mIoU: 0.4135\n",
            "‚úÖ Epoch 5 | Train Loss: 0.1345 | Val Loss: 0.2272 | mIoU: 0.4135 | Free GPU: 13.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Best model saved at epoch 6 | Val Loss: 0.2267 | mIoU: 0.4211\n",
            "‚úÖ Epoch 6 | Train Loss: 0.1172 | Val Loss: 0.2267 | mIoU: 0.4211 | Free GPU: 13.26 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 7 | Train Loss: 0.1051 | Val Loss: 0.2282 | mIoU: 0.4178 | Free GPU: 13.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 8 | Train Loss: 0.0974 | Val Loss: 0.2318 | mIoU: 0.4226 | Free GPU: 13.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 9 | Train Loss: 0.0898 | Val Loss: 0.2333 | mIoU: 0.4205 | Free GPU: 13.27 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 10 | Train Loss: 0.0846 | Val Loss: 0.2360 | mIoU: 0.4231 | Free GPU: 13.25 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 11 | Train Loss: 0.0798 | Val Loss: 0.2407 | mIoU: 0.4230 | Free GPU: 13.30 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 12 | Train Loss: 0.0755 | Val Loss: 0.2417 | mIoU: 0.4231 | Free GPU: 13.23 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 13 | Train Loss: 0.0743 | Val Loss: 0.2445 | mIoU: 0.4267 | Free GPU: 13.19 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 14 | Train Loss: 0.0714 | Val Loss: 0.2417 | mIoU: 0.4271 | Free GPU: 13.19 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 15 | Train Loss: 0.0675 | Val Loss: 0.2453 | mIoU: 0.4246 | Free GPU: 13.21 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 16 | Train Loss: 0.0639 | Val Loss: 0.2459 | mIoU: 0.4284 | Free GPU: 13.32 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 17 | Train Loss: 0.0612 | Val Loss: 0.2509 | mIoU: 0.4267 | Free GPU: 13.25 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 18 | Train Loss: 0.0587 | Val Loss: 0.2506 | mIoU: 0.4287 | Free GPU: 13.25 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 19 | Train Loss: 0.0570 | Val Loss: 0.2534 | mIoU: 0.4263 | Free GPU: 13.28 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 20 | Train Loss: 0.0554 | Val Loss: 0.2579 | mIoU: 0.4287 | Free GPU: 13.35 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 21 | Train Loss: 0.0535 | Val Loss: 0.2599 | mIoU: 0.4269 | Free GPU: 13.25 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 22 | Train Loss: 0.0519 | Val Loss: 0.2655 | mIoU: 0.4260 | Free GPU: 13.26 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 23 | Train Loss: 0.0505 | Val Loss: 0.2626 | mIoU: 0.4287 | Free GPU: 13.34 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 24 | Train Loss: 0.0489 | Val Loss: 0.2707 | mIoU: 0.4301 | Free GPU: 13.28 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 25 | Train Loss: 0.0482 | Val Loss: 0.2606 | mIoU: 0.4295 | Free GPU: 13.26 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 26 | Train Loss: 0.0470 | Val Loss: 0.2718 | mIoU: 0.4282 | Free GPU: 13.28 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 27 | Train Loss: 0.0459 | Val Loss: 0.2731 | mIoU: 0.4271 | Free GPU: 13.25 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 28 | Train Loss: 0.0452 | Val Loss: 0.2745 | mIoU: 0.4304 | Free GPU: 13.30 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 29 | Train Loss: 0.0445 | Val Loss: 0.2754 | mIoU: 0.4313 | Free GPU: 13.26 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 30 | Train Loss: 0.0435 | Val Loss: 0.2749 | mIoU: 0.4305 | Free GPU: 13.25 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 31 | Train Loss: 0.0429 | Val Loss: 0.2776 | mIoU: 0.4311 | Free GPU: 13.32 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 32 | Train Loss: 0.0422 | Val Loss: 0.2748 | mIoU: 0.4325 | Free GPU: 13.21 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 33 | Train Loss: 0.0412 | Val Loss: 0.2818 | mIoU: 0.4317 | Free GPU: 13.28 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 34 | Train Loss: 0.0403 | Val Loss: 0.2844 | mIoU: 0.4318 | Free GPU: 13.26 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 35 | Train Loss: 0.0396 | Val Loss: 0.2891 | mIoU: 0.4294 | Free GPU: 13.23 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 36 | Train Loss: 0.0390 | Val Loss: 0.2923 | mIoU: 0.4282 | Free GPU: 13.27 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 37 | Train Loss: 0.0386 | Val Loss: 0.2836 | mIoU: 0.4320 | Free GPU: 13.26 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 38 | Train Loss: 0.0383 | Val Loss: 0.2893 | mIoU: 0.4303 | Free GPU: 13.25 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 39 | Train Loss: 0.0379 | Val Loss: 0.2885 | mIoU: 0.4318 | Free GPU: 13.30 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 40 | Train Loss: 0.0373 | Val Loss: 0.2910 | mIoU: 0.4328 | Free GPU: 13.24 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 41 | Train Loss: 0.0368 | Val Loss: 0.2946 | mIoU: 0.4296 | Free GPU: 13.25 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 42 | Train Loss: 0.0362 | Val Loss: 0.2859 | mIoU: 0.4343 | Free GPU: 13.30 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 43 | Train Loss: 0.0361 | Val Loss: 0.2952 | mIoU: 0.4316 | Free GPU: 13.26 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 44 | Train Loss: 0.0364 | Val Loss: 0.2975 | mIoU: 0.4298 | Free GPU: 13.32 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 45 | Train Loss: 0.0356 | Val Loss: 0.2979 | mIoU: 0.4321 | Free GPU: 13.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 46 | Train Loss: 0.0350 | Val Loss: 0.3001 | mIoU: 0.4301 | Free GPU: 13.30 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 47 | Train Loss: 0.0346 | Val Loss: 0.2983 | mIoU: 0.4329 | Free GPU: 13.33 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 48 | Train Loss: 0.0340 | Val Loss: 0.2983 | mIoU: 0.4340 | Free GPU: 13.21 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 49 | Train Loss: 0.0336 | Val Loss: 0.3084 | mIoU: 0.4317 | Free GPU: 13.18 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 50 | Train Loss: 0.0335 | Val Loss: 0.3051 | mIoU: 0.4328 | Free GPU: 13.21 GB\n",
            "üèÅ Training complete.\n",
            "üìâ Best Validation Loss: 0.2267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3krw4L3lDivL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# ‚úÖ Destination path on the Drive\n",
        "drive_path = \"/content/drive/MyDrive/Semantic_Segmentation/best_deeplabv2_cityscapes.pth\"\n",
        "\n",
        "# ‚úÖ Copy model from Colab to Drive\n",
        "shutil.copy(\"/content/best_deeplabv2_cityscapes.pth\", drive_path)\n",
        "\n",
        "print(\"‚úÖ Model saved to Google Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiI81lnxDifS",
        "outputId": "7cd04bfd-469d-4dbd-a47e-2f61ef411b34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model saved to Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Latency"
      ],
      "metadata": {
        "id": "Q18ylqfnFGft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "model.eval()  # ‚úÖ inference mode\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 512, 1024).to(device)\n",
        "iterations = 1000\n",
        "\n",
        "latencies = []\n",
        "fps_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(iterations):\n",
        "        start = time.time()\n",
        "        _ = model(dummy_input)\n",
        "        end = time.time()\n",
        "\n",
        "        latency = end - start\n",
        "        latencies.append(latency)\n",
        "        fps_values.append(1 / latency)\n",
        "\n",
        "mean_latency_ms = np.mean(latencies) * 1000\n",
        "std_latency_ms = np.std(latencies) * 1000\n",
        "mean_fps = np.mean(fps_values)\n",
        "std_fps = np.std(fps_values)\n",
        "\n",
        "print(f\"‚è±Ô∏è Latency: {mean_latency_ms:.2f} ¬± {std_latency_ms:.2f} ms/image\")\n",
        "print(f\"üöÄ FPS: {mean_fps:.2f} ¬± {std_fps:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjd0XV1zFH5S",
        "outputId": "7a01a5a9-607c-4171-84cc-c78e812b7b63"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è±Ô∏è Latency: 234.68 ¬± 12.26 ms/image\n",
            "üöÄ FPS: 4.41 ¬± 3.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flops"
      ],
      "metadata": {
        "id": "IhbI03R8H1pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Install fvcore if not already\n",
        "!pip install -q fvcore\n",
        "\n",
        "# ‚úÖ Count FLOPs\n",
        "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "\n",
        "model.eval()\n",
        "dummy_input = torch.randn(1, 3, 512, 1024).to(device)\n",
        "\n",
        "flops = FlopCountAnalysis(model, dummy_input)\n",
        "print(flop_count_table(flops, max_depth=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jptRpflPH2kU",
        "outputId": "94d300e0-c562-431f-807b-98555f80d80a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "| module              | #parameters or shape   | #flops   |\n",
            "|:--------------------|:-----------------------|:---------|\n",
            "| model               | 43.901M                | 0.375T   |\n",
            "|  conv1              |  9.408K                |  1.233G  |\n",
            "|  bn1                |  0.128K                |  16.777M |\n",
            "|  layer1             |  0.216M                |  7.155G  |\n",
            "|  layer2             |  1.22M                 |  10.226G |\n",
            "|  layer3             |  26.09M                |  0.219T  |\n",
            "|  layer4             |  14.965M               |  0.125T  |\n",
            "|  layer6.conv2d_list |  1.401M                |  11.746G |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Model Parameters"
      ],
      "metadata": {
        "id": "WoZfszOYISIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Count total parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"üì¶ Total Trainable Parameters: {total_params / 1e6:.2f} Million\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nFpAMcxITFu",
        "outputId": "32891970-9922-43a8-9efa-09fbdff7068f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Total Trainable Parameters: 43.80 Million\n"
          ]
        }
      ]
    }
  ]
}